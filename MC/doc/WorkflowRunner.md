This is the documentation for the `o2_dpg_workflow_runner.py` tool.

# Purpose

Execution of O2 DPG workflows under resource constraints, where possibly tasks
will be scheduled in parallel.
In principle, this can serve to schedule any kind of directed acycling graph (DAG)
workflow, not just DPG ones. The tool takes care of **how** something is executed,
not **what** is executed or how it is configured.

# More detailed description

The tool provides features of a typical data/task pipelining environment
using a DAG approach. It allows to separate the concerns of workflow setup and workflow running - and as such
allows to optimize workflow deployment during execution.
It is inspired by similar ideas in ALICE alibuild and the ALILE Data Processing Layer (DPL) but differs in some aspects:

   * allow to schedule tasks in parallel
   * be resource aware (e.g., don't schedule 2 tasks requiring large memory at the same time)
   * allow to schedule any task, be it a simple executable, bash script, ROOT macro, or DPL workflow.

The goals of the tool are:

   * automatic task parallelization (within or across timeframes)
   * scale from running on few-core GRID nodes to large HPC cores (via automatic timeframe parallelism)
   * restart-from-failure features
   * skip-done features when run again with same input
   * if input changes, rerun only affected stages
   * automatic task skipping in case it is not relevant for the goal
   * file provenance tracking, cleanup of intermediate products
   * dream: automatic DPL fusion/pipelining (say DPL workflow for TPC digitization and TPC reco) when we don't need the intermediate files
   on disc

# Workflow specification

The tool runs workflows, specified in json format. The specification of this format is
still in development. Currently, it follows the following scheme:

```
{
  "stages": [
    {
      "name": "task1",
      "cmd": "o2-sim-serial -n 1 -m PIPE ITS",
      "needs": [],
      "resources": {
        "cpu": -1,
        "mem": -1
      },
      "timeframe": 1,
      "labels": [ "MC" ],
      "cwd": "tf1"
    },
    {
      "name": "task2",
      "cmd": "o2-sim-digitizer-workflow"
      "needs": [ "task1" ],
      "resources": {
        "cpu": -1,
        "mem": -1
      },
      "timeframe": 1,
      "labels": [ "DIGI", "ITS" ],
      "cwd": "tf1"
    }]
  "comments" : "A DPG MC workflow for production FOO"
}
```
Here, 2 tasks `task1` and `task2` a specified, where task1 is running a simple MC transport simulation and task2 a digitization process.
Naturally, task2 depends on task1 expressed via the `needs` list.

Further keys in this format are:
| field | description |
| ----- | ----------- |
| `resources` | estimated resource usage for average cpu load (250 = 2.5 CPUs) and maximal memory in MB. Used for scheduling. -1 is used for unknown or don't care. |
| `timeframe` | timeframe index or -1 if not associated to any timeframe. May have influence on order of execution (prefer finish timeframe first) |
| `cwd` | the workding directory where this is to be executed |
| `label` | a list labels, describing this stage. Can be used to execute workfow in stages (such as 'do all digitization', 'run everthing for ITS' 

A workflow is generated by different tools. A current example following the PWGHF embedding exercise can be found here https://github.com/AliceO2Group/O2DPG/blob/master/MC/run/PWGHF/create_embedding_workflow.py

## Example usage

Run workflow in a given file
```
alienv enter O2/latest O2DPG/latest
o2_dpg_workflow_runner.py -f workflow_sim.json
```

Show what you would run
```
o2_dpg_workflow_runner.py -f workflow_sim.json --dry-run
```

## Future targeted features:

Run until everyting marked "RECO" is done
```
o2_dpg_workflow_runner.py -f workflow_sim.json --stages RECO
```

Rerun worflow until AOD, skipping all tasks already done
```
o2_dpg_workflow_runner.py -f workflow_sim.json --stages AOD --skip-done
```
